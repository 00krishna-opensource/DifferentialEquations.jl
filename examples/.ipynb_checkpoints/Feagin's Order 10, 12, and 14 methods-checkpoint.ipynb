{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feagin's Order 10, 12, and 14 Methods\n",
    "\n",
    "DifferentialEquations.jl includes Feagin's explicit Runge-Kutta methods of orders 10/8, 12/10, and 14/12. These methods have such high order that it's pretty much required that one uses numbers with more precision than Float64. As a prerequisite reference on how to use arbitrary number systems (including higher precision) in the numerical solvers, please see the Solving Equations in With Chosen Number Types notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigation of the Method's Error\n",
    "\n",
    "We can use Feagin's order 16 method as follows. Let's use the twoDimlinearODEExample from previous examples. Like in the Solving Equations in With Chosen Number Types notebook, we change the initial condition to BigFloats to tell the solver to use BigFloat types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "using DifferentialEquations\n",
    "prob = prob_ode_2Dlinear\n",
    "sol =solve(prob::ODEProblem,Δt=1//16,alg=:Feagin14,adaptive=false);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's print the errors and find out how accurate it is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dict(:l∞=>1.834920846276128345768456848043647539688554668437028441297187579147565729397152e-23,:final=>8.325176120322795020599060812643279837932924795032522034303070091950178990420393e-24,:l2=>5.158396995918330946892812981239371274402680113660348929191427359885823789028183e-24)"
     ]
    }
   ],
   "source": [
    "print(sol.errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare that to machine $\\epsilon$ for Float64:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.220446049250313e-16"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eps(Float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The error for Feagin's method when the stepsize is 1/16 is 8 orders of magnitude below machine $\\epsilon$! However, that is dependent on the stepsize. If we instead use adaptive timestepping with the default tolerances [and set the internalnorm=1 to avoid [this issue](https://github.com/JuliaLang/julia/issues/17728)], we get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "LoadError: UndefVarError: Δts not defined\nwhile loading In[4], in expression starting on line 1",
     "output_type": "error",
     "traceback": [
      "LoadError: UndefVarError: Δts not defined\nwhile loading In[4], in expression starting on line 1",
      ""
     ]
    }
   ],
   "source": [
    "sol =solve(prob::ODEProblem,Δt=Δts[1],alg=:Feagin14,adaptive=true,internalnorm=1); \n",
    "println(sol.errors); print(\"The length was $(length(sol))\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that when the stepsize is much higher, the error goes up quickly as well. These super high order methods are best when used to gain really accurate approximations (using still modest timesteps). Some examples of where such precision is necessary is astrodynamics where the many-body problem is highly chaotic and thus sensitive to small errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convergence Test\n",
    "\n",
    "The Order 14 method is awesome, but we need to make sure it's really that awesome. The following convergence test is used in the package tests in order to make sure the implementation is correct. Note that all methods have such tests in place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DifferentialEquations.ConvergenceSimulation of length 7.\n",
       "Convergence Estimates: (l∞,14.290261124780095) (final,14.290261124780095) (l2,14.29968233607688)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Δts = 1.//2.^(10:-1:4)\n",
    "sim = test_convergence(Δts,prob,alg=:Feagin14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a better view of what's going on, let's plot the simulation results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Plots.plotly()\n",
    "plot(sim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the PyPlot backend does not show this correctly. However, it's the only Plots.jl backed whose picture saves in the notebook in a format which Github can render. Therefore I can use `Plots.plotly()` to change to the Plotly backend and save the plot. The saved plot looks like:\n",
    "\n",
    "![FeaginConvergence](https://raw.githubusercontent.com/JuliaDiffEq/DifferentialEquations.jl/master/examples/plots/FeaginConvergence.png)\n",
    "\n",
    "This is a clear trend indicating that the convergence is truely Order 14. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.5.0-rc3",
   "language": "julia",
   "name": "julia-0.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
